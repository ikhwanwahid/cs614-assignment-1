{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS614 Individual Assignment: Fine-Tuning an LLM for Medical Question Answering\n",
    "\n",
    "**Student:** Ikhwan Wahid  \n",
    "**Module:** CS614 - Generative AI with LLMs  \n",
    "**Date:** February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Task\n",
    "\n",
    "The goal of this assignment is to fine-tune a pre-trained large language model (LLM) to improve its performance on a domain-specific task. Specifically, we fine-tune **Mistral-7B-Instruct-v0.3** on the **MedQA-USMLE** dataset — a collection of 4-option multiple-choice questions from the United States Medical Licensing Examination (USMLE).\n",
    "\n",
    "The task is framed as a classification problem: given a clinical vignette and four answer options (A, B, C, D), the model must select the single best answer. We use **QLoRA** (Quantized Low-Rank Adaptation) to make fine-tuning feasible on a single GPU, and evaluate across **6 hyperparameter configurations** to study the effect of LoRA rank, learning rate, training duration, and regularization.\n",
    "\n",
    "We also conduct additional analyses beyond the core fine-tuning:\n",
    "- **Zero-shot and 3-shot baselines** to establish pre-training performance\n",
    "- **Per-topic accuracy breakdown** across 13 medical specialties\n",
    "- **Error analysis** with confusion matrices\n",
    "- **Confidence calibration** (Expected Calibration Error)\n",
    "- **Answer position bias analysis** with chi-squared statistical tests\n",
    "- **Prompt template sensitivity** testing across 4 different system prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Dataset\n",
    "\n",
    "**Source:** [`GBaker/MedQA-USMLE-4-options-hf`](https://huggingface.co/datasets/GBaker/MedQA-USMLE-4-options-hf) on HuggingFace Hub\n",
    "\n",
    "| Split | Examples |\n",
    "|-------|----------|\n",
    "| Train | 10,178 |\n",
    "| Validation | 1,272 |\n",
    "| Test | 1,273 |\n",
    "\n",
    "Each example contains:\n",
    "- A clinical vignette (`sent1`) describing a patient scenario\n",
    "- Four answer options (`ending0` through `ending3`)\n",
    "- A gold label (0-3, mapped to A-D)\n",
    "\n",
    "The questions are drawn from USMLE Step 1, Step 2, and Step 3 exams, covering a broad range of medical topics. Using a keyword-based topic classifier, we identified 13 medical specialties in the test set:\n",
    "\n",
    "| Topic | Test Examples | % of Test Set |\n",
    "|-------|:---:|:---:|\n",
    "| Other (General Medicine) | 145 | 11.4% |\n",
    "| Gastroenterology | 157 | 12.3% |\n",
    "| Cardiology | 158 | 12.4% |\n",
    "| Infectious Disease | 81 | 6.4% |\n",
    "| Neurology | 65 | 5.1% |\n",
    "| Pulmonology | 90 | 7.1% |\n",
    "| Nephrology | 59 | 4.6% |\n",
    "| Endocrinology | 57 | 4.5% |\n",
    "| Hematology | 46 | 3.6% |\n",
    "| Obstetrics/Gynecology | 108 | 8.5% |\n",
    "| Psychiatry | 68 | 5.3% |\n",
    "| Oncology | 50 | 3.9% |\n",
    "| Pharmacology | 8 | 0.6% |\n",
    "\n",
    "The answer label distribution in the training set is approximately uniform across A/B/C/D, which means no class rebalancing was needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Model Choice\n",
    "\n",
    "### Base Model: Mistral-7B-Instruct-v0.3\n",
    "\n",
    "We selected [`mistralai/Mistral-7B-Instruct-v0.3`](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) for several reasons:\n",
    "\n",
    "1. **7B parameters** strikes a balance between capability and trainability on a single GPU\n",
    "2. **Instruction-tuned** — the model already understands the instruct format (`[INST] ... [/INST]`), which means it can follow prompts out of the box\n",
    "3. **Strong general reasoning** — Mistral-7B outperforms many larger models on standard benchmarks\n",
    "4. **Wide QLoRA support** — well-tested with PEFT, bitsandbytes, and trl libraries\n",
    "\n",
    "### Why QLoRA?\n",
    "\n",
    "Full fine-tuning of a 7B parameter model requires approximately **56 GB of VRAM** (7B params x 4 bytes for weights + 4 bytes for AdamW optimizer states). This exceeds even an 80GB H100 once activations and gradients are included. QLoRA makes fine-tuning feasible through three techniques:\n",
    "\n",
    "| Technique | Effect |\n",
    "|-----------|--------|\n",
    "| **4-bit NF4 quantization** | Compresses base model from ~14 GB (FP16) to ~4 GB in GPU memory |\n",
    "| **LoRA adapters** | Injects small trainable matrices (1-4% of total params), leaving the quantized base frozen |\n",
    "| **Gradient checkpointing** | Trades compute for memory by recomputing activations during backward pass |\n",
    "\n",
    "This combination reduces VRAM usage to ~15-20 GB, fitting comfortably on a single GPU.\n",
    "\n",
    "### LoRA Configuration\n",
    "\n",
    "We target **all 7 linear layers** in each Mistral transformer block:\n",
    "\n",
    "```\n",
    "Target modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj\n",
    "```\n",
    "\n",
    "This is more comprehensive than the common approach of only targeting attention projections (`q_proj`, `v_proj`), and gives the adapter more capacity to learn task-specific representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Fine-Tuning Process\n",
    "\n",
    "### Training Format\n",
    "\n",
    "Each training example is formatted in the Mistral instruct template:\n",
    "\n",
    "```\n",
    "<s>[INST] You are a medical expert. Answer the following USMLE-style\n",
    "multiple-choice question by selecting the single best answer.\n",
    "Respond with ONLY the letter (A, B, C, or D) of the correct answer.\n",
    "\n",
    "{clinical vignette}\n",
    "\n",
    "A) {option_0}\n",
    "B) {option_1}\n",
    "C) {option_2}\n",
    "D) {option_3} [/INST] {answer_letter}</s>\n",
    "```\n",
    "\n",
    "The model is trained to predict only the answer letter (A/B/C/D) — a single token — after seeing the full prompt.\n",
    "\n",
    "### Hyperparameter Sweep\n",
    "\n",
    "We trained **6 configurations** that systematically vary LoRA rank, learning rate, training duration, and dropout:\n",
    "\n",
    "| Config | LoRA Rank (r) | Alpha | Learning Rate | Epochs | Dropout | Trainable Params | What It Tests |\n",
    "|--------|:---:|:---:|:---:|:---:|:---:|:---:|-------|\n",
    "| 1 (Baseline) | 16 | 32 | 2e-4 | 2 | 0.05 | 42M (1.10%) | Standard QLoRA defaults |\n",
    "| 2 (Low Rank) | 8 | 16 | 2e-4 | 2 | 0.05 | 21M (0.55%) | Fewer params sufficient? |\n",
    "| 3 (High Rank) | 64 | 128 | 1e-4 | 2 | 0.05 | 168M (4.27%) | More capacity helps? |\n",
    "| 4 (Low LR) | 16 | 32 | 5e-5 | 3 | 0.05 | 42M (1.10%) | Slower, more stable learning? |\n",
    "| 5 (Extended) | 16 | 32 | 2e-4 | 3 | 0.05 | 42M (1.10%) | More epochs help? |\n",
    "| 6 (Aggressive) | 32 | 64 | 3e-4 | 2 | 0.10 | 84M (2.18%) | Speed + regularization |\n",
    "\n",
    "**Fixed settings across all configs:**\n",
    "- Effective batch size: 16 (batch=4 x gradient accumulation=4)\n",
    "- Optimizer: Paged AdamW 8-bit\n",
    "- LR scheduler: Cosine with 5% warmup\n",
    "- Max sequence length: 1024 tokens\n",
    "- Weight decay: 0.01\n",
    "- Early stopping: patience = 3 evaluation steps (every 100 training steps)\n",
    "- Precision: BFloat16\n",
    "- Quantization: NF4 with double quantization\n",
    "\n",
    "### Training Results\n",
    "\n",
    "| Config | Best Eval Loss | Training Time | Steps Before Early Stop |\n",
    "|--------|:---:|:---:|:---:|\n",
    "| 1 (Baseline) | 0.9594 | 29.5 min | ~600 |\n",
    "| 2 (Low Rank) | 0.9583 | 29.6 min | ~600 |\n",
    "| 3 (High Rank) | 0.9527 | 30.0 min | ~600 |\n",
    "| 4 (Low LR) | **0.9515** | 49.2 min | ~1500 |\n",
    "| 5 (Extended) | 0.9685 | 29.6 min | ~600 |\n",
    "| 6 (Aggressive) | 0.9810 | 42.9 min | ~600 |\n",
    "\n",
    "**Key observations from training:**\n",
    "- **Early stopping activated in all configs**, preventing overfitting. No config completed its full epoch budget.\n",
    "- **Config 4** (low LR) trained for the most steps (~1500) because the slower learning rate allowed gradual improvement without triggering early stopping.\n",
    "- **Configs 5 and 6** had the worst eval losses, confirming that higher learning rates lead to faster overfitting.\n",
    "- **Total training time** for all 6 configs: approximately **3.5 hours** on an NVIDIA H100 80GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Evaluation\n",
    "\n",
    "### Evaluation Setup\n",
    "\n",
    "We evaluate three approaches on the **full test set** (1,273 examples):\n",
    "\n",
    "1. **Zero-shot** — Base Mistral-7B with no examples, just the system prompt\n",
    "2. **3-shot** — Base Mistral-7B with 3 random training examples as in-context exemplars\n",
    "3. **Fine-tuned** — Best QLoRA config (config 4) applied to the base model\n",
    "\n",
    "Inference uses greedy decoding (`do_sample=False`) with `max_new_tokens=5`. The generated text is parsed to extract the answer letter using a multi-strategy regex parser (exact first-char match, \"The answer is X\" patterns, standalone letter detection).\n",
    "\n",
    "### Main Results\n",
    "\n",
    "| Metric | Zero-Shot | 3-Shot | Fine-Tuned | Delta (FT vs ZS) |\n",
    "|--------|:---:|:---:|:---:|:---:|\n",
    "| **Accuracy** | 49.10% | 49.02% | **57.42%** | **+8.32 pp** |\n",
    "| **Macro F1** | 0.4929 | 0.4888 | **0.5695** | +0.0766 |\n",
    "| **Extraction Failure Rate** | 1.18% | 1.65% | **0.16%** | -1.02 pp |\n",
    "\n",
    "### Validation Accuracy Across All 6 Configs\n",
    "\n",
    "| Config | Val Accuracy | Val Macro F1 | Extraction Failures |\n",
    "|--------|:---:|:---:|:---:|\n",
    "| **4 (Low LR)** | **57.39%** | **0.5716** | **0.00%** |\n",
    "| 3 (High Rank) | 56.68% | 0.5667 | 0.00% |\n",
    "| 2 (Low Rank) | 56.29% | 0.5620 | 0.00% |\n",
    "| 1 (Baseline) | 55.82% | 0.5562 | 0.00% |\n",
    "| 5 (Extended) | 52.99% | 0.5283 | 0.00% |\n",
    "| 6 (Aggressive) | 51.34% | 0.5115 | 0.00% |\n",
    "\n",
    "### Per-Class Performance (Fine-Tuned, Test Set)\n",
    "\n",
    "| Answer | Precision | Recall | F1-Score | Support |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| A | 0.62 | 0.58 | 0.60 | 353 |\n",
    "| B | 0.52 | 0.59 | 0.55 | 309 |\n",
    "| C | 0.61 | 0.63 | 0.62 | 346 |\n",
    "| D | 0.54 | 0.48 | 0.50 | 265 |\n",
    "\n",
    "Answer **D** has the lowest recall (0.48), meaning the model fails to identify D as correct ~52% of the time. This is consistent with the position bias analysis in Section 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Topic Accuracy\n",
    "\n",
    "Fine-tuning improved accuracy across **all 13 medical topics**:\n",
    "\n",
    "| Topic | Zero-Shot | Fine-Tuned | Delta |\n",
    "|-------|:---:|:---:|:---:|\n",
    "| Obstetrics/Gynecology | 52.8% | **63.0%** | +10.2 |\n",
    "| Cardiology | 50.2% | **62.0%** | +11.8 |\n",
    "| Psychiatry | 47.1% | **61.8%** | **+14.7** |\n",
    "| Other (General Medicine) | 59.3% | 60.0% | +0.7 |\n",
    "| Oncology | 54.0% | 60.0% | +6.0 |\n",
    "| Gastroenterology | 53.5% | 59.2% | +5.7 |\n",
    "| Pulmonology | 45.6% | 55.6% | +10.0 |\n",
    "| Nephrology | 49.2% | 54.2% | +5.1 |\n",
    "| Infectious Disease | 46.9% | 53.1% | +6.2 |\n",
    "| Endocrinology | 40.4% | 52.6% | **+12.3** |\n",
    "| Hematology | 37.0% | 50.0% | **+13.0** |\n",
    "| Neurology | 43.1% | 47.7% | +4.6 |\n",
    "| Pharmacology | 25.0% | 37.5% | +12.5 |\n",
    "\n",
    "**Largest gains:** Psychiatry (+14.7 pp), Hematology (+13.0 pp), Endocrinology (+12.3 pp), Pharmacology (+12.5 pp). These topics likely had the most room for the model to learn answer formatting and basic pattern recognition.\n",
    "\n",
    "**Weakest after fine-tuning:** Pharmacology (37.5%, but only 8 test examples) and Neurology (47.7%). These topics may require specialized reasoning that the base model's pre-training did not cover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "Of 1,273 test examples, the fine-tuned model made **542 errors** (42.6% error rate):\n",
    "\n",
    "| Error Type | Count |\n",
    "|-----------|:---:|\n",
    "| Substantive errors (wrong answer selected) | 540 |\n",
    "| Extraction failures (no valid A/B/C/D produced) | 2 |\n",
    "\n",
    "**Most confused answer pairs** (gold -> predicted):\n",
    "\n",
    "| Gold | Predicted | Count |\n",
    "|:---:|:---:|:---:|\n",
    "| A | B | 62 |\n",
    "| C | B | 55 |\n",
    "| D | B | 51 |\n",
    "| A | C | 48 |\n",
    "| B | C | 48 |\n",
    "\n",
    "The model disproportionately predicts **B** when it is wrong, consistent with the position bias analysis below.\n",
    "\n",
    "**Error rate by topic** (highest to lowest):\n",
    "\n",
    "| Topic | Error Rate |\n",
    "|-------|:---:|\n",
    "| Pharmacology | 62.5% |\n",
    "| Neurology | 52.3% |\n",
    "| Hematology | 50.0% |\n",
    "| Endocrinology | 47.4% |\n",
    "| Infectious Disease | 46.9% |\n",
    "| Nephrology | 45.8% |\n",
    "| Pulmonology | 44.4% |\n",
    "| Gastroenterology | 40.8% |\n",
    "| Other | 40.0% |\n",
    "| Oncology | 40.0% |\n",
    "| Psychiatry | 38.2% |\n",
    "| Cardiology | 38.0% |\n",
    "| Obstetrics/Gynecology | 37.0% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Calibration\n",
    "\n",
    "We computed the model's confidence by examining the softmax probability over the A/B/C/D token logits at the first generated position:\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|:---:|\n",
    "| Expected Calibration Error (ECE) | **0.2536** |\n",
    "| Avg. confidence on correct predictions | 57.97% |\n",
    "| Avg. confidence on incorrect predictions | 54.42% |\n",
    "\n",
    "The ECE of 0.254 indicates **poor calibration** — the model is overconfident. It assigns high confidence even when wrong (54.4% avg), and the gap between confidence on correct vs incorrect predictions is only 3.6 percentage points. A well-calibrated model should show a much larger gap.\n",
    "\n",
    "The calibration curve shows that for predictions with >90% confidence, the model is only correct ~41% of the time — a severe overconfidence problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Results & Analysis\n",
    "\n",
    "### 6.1 Where the Fine-Tuned Model Improved\n",
    "\n",
    "**1. Overall accuracy: +8.3 percentage points over zero-shot baseline.**\n",
    "\n",
    "The fine-tuned model (57.4%) significantly outperformed both the zero-shot (49.1%) and 3-shot (49.0%) baselines. This confirms that QLoRA fine-tuning is effective at adapting a general-purpose LLM to the medical MCQ domain, even with only 1.1% of parameters being trainable.\n",
    "\n",
    "**2. Extraction failures nearly eliminated.**\n",
    "\n",
    "The base model failed to produce a valid A/B/C/D answer 1.2-1.7% of the time (15-21 examples). After fine-tuning, this dropped to 0.16% (2 examples). The model learned the expected output format perfectly, which is a direct benefit of supervised fine-tuning on structured answer templates.\n",
    "\n",
    "**3. Improvement across all 13 medical topics.**\n",
    "\n",
    "No topic regressed after fine-tuning. The gains ranged from +0.7 pp (General Medicine, already the strongest) to +14.7 pp (Psychiatry). This broad improvement suggests the fine-tuning transferred general medical reasoning rather than memorizing topic-specific patterns.\n",
    "\n",
    "**4. Reduced answer position bias.**\n",
    "\n",
    "The zero-shot model had a severe positional bias, over-predicting D by 134 examples (chi-squared = 55.0, p < 0.001). Fine-tuning reduced this to a milder B-bias of +42 examples (chi-squared = 29.9, p < 0.001). While still statistically non-uniform, the fine-tuned model's predictions are much closer to the gold label distribution.\n",
    "\n",
    "**5. Robust to prompt template changes.**\n",
    "\n",
    "Testing 4 different system prompts on the fine-tuned model yielded accuracy within a narrow 0.8% band:\n",
    "\n",
    "| Prompt Template | Accuracy |\n",
    "|----------------|:---:|\n",
    "| Original (training prompt) | 57.42% |\n",
    "| Minimal (\"Answer with only the letter\") | 57.50% |\n",
    "| CoT-style (\"Think step by step\") | 56.87% |\n",
    "| Role-emphasis (\"experienced physician\") | **57.66%** |\n",
    "\n",
    "This confirms the model learned to answer medical questions generally, rather than memorizing the specific training prompt wording. The role-emphasis prompt slightly outperformed the original, suggesting the model responds to contextual priming even after fine-tuning.\n",
    "\n",
    "### 6.2 Where the Fine-Tuned Model Did Not Improve (or Showed Limitations)\n",
    "\n",
    "**1. Accuracy ceiling at ~57%, regardless of hyperparameters.**\n",
    "\n",
    "All 6 configurations converged to validation accuracy between 51.3% and 57.4%, with best eval losses within a narrow range (0.95-0.98). This ceiling is likely set by Mistral-7B's pre-trained medical knowledge, not the fine-tuning method. QLoRA can teach the output format and sharpen existing knowledge, but cannot inject new medical facts that were not learned during pre-training.\n",
    "\n",
    "**2. Few-shot prompting provided no benefit.**\n",
    "\n",
    "The 3-shot baseline (49.0%) performed marginally *worse* than zero-shot (49.1%), contradicting the common expectation that in-context examples help. For a 7B model on complex medical reasoning, the exemplars may consume too much of the context window or introduce confusing patterns. This contrasts with larger models (e.g., GPT-4) where few-shot prompting is highly effective.\n",
    "\n",
    "**3. Persistent answer position bias.**\n",
    "\n",
    "Despite reducing bias severity, the fine-tuned model still exhibits non-uniform prediction distributions (chi-squared = 29.9, p < 0.001). It over-predicts B (+42 over gold) and under-predicts D (-30 under gold). This means answer D has only 0.48 recall — the model fails to identify the correct answer almost half the time when D is correct.\n",
    "\n",
    "**4. Severe overconfidence (ECE = 0.254).**\n",
    "\n",
    "The model cannot reliably distinguish when it is right vs wrong. Average confidence for correct predictions (58.0%) is barely higher than for incorrect predictions (54.4%). In the highest confidence bin (>90%), accuracy is only 41.4%. This means the model's confidence scores are essentially meaningless for decision-making.\n",
    "\n",
    "**5. Pharmacology and Neurology remain weak.**\n",
    "\n",
    "Despite fine-tuning, Pharmacology (37.5%) and Neurology (47.7%) remain below 50% accuracy. Pharmacology improved from 25% (random-chance level) to 37.5%, but the small sample size (8 examples) makes this unreliable. Neurology's modest +4.6 pp gain suggests the base model lacks foundational neurological reasoning.\n",
    "\n",
    "**6. Aggressive hyperparameters hurt performance.**\n",
    "\n",
    "Config 6 (lr=3e-4, r=32, dropout=0.1) was the worst performer at 51.3% — only 2 pp above zero-shot. Config 5 (3 epochs at lr=2e-4) also underperformed at 53.0%. Both showed severe train-eval loss divergence within ~600 steps, confirming that overfitting is the primary risk when fine-tuning LLMs on domain-specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Observed Limitations and Failure Modes\n",
    "\n",
    "1. **Knowledge ceiling from pre-training.** The ~57% accuracy ceiling is determined by what the base model learned during pre-training, not by the fine-tuning method. All 6 configs converge to similar eval losses (~0.95-0.98), suggesting QLoRA adapts output formatting and sharpens existing knowledge but cannot compensate for missing medical facts.\n",
    "\n",
    "2. **Answer position bias (D under-predicted).** The model under-predicts D by 30 examples, resulting in D having the lowest recall (0.48) of any answer position. The confusion matrix shows that when D is the correct answer, the model most often incorrectly predicts B (51 times). This systematic pattern suggests the model may be learning positional shortcuts rather than fully understanding answer content.\n",
    "\n",
    "3. **Overconfidence renders confidence scores unusable.** With ECE of 0.254 and near-identical confidence for correct (58.0%) and incorrect (54.4%) predictions, the model's uncertainty estimates provide almost no signal. In a medical setting, this is particularly dangerous as users cannot rely on confidence scores to flag uncertain predictions.\n",
    "\n",
    "4. **CoT prompting slightly hurts accuracy.** The chain-of-thought prompt (56.87%) slightly underperformed the original prompt (57.42%). Since the model was trained to output a single letter and we limit generation to 5 tokens, the CoT instruction creates a mismatch — the model cannot actually reason step-by-step within the token budget.\n",
    "\n",
    "5. **Heuristic topic classifier.** Our keyword-based topic tagger is approximate — questions spanning multiple specialties (e.g., a cardiology question involving pharmacology) may be misclassified, affecting per-topic accuracy estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Alternative Design Choices\n",
    "\n",
    "To push beyond the current accuracy ceiling, several alternative approaches could be considered:\n",
    "\n",
    "| Alternative | Expected Impact | Rationale |\n",
    "|------------|:-:|---|\n",
    "| **Answer shuffling during training** | +2-5% | Randomly permuting option positions (A/B/C/D) during training forces the model to learn answer content rather than positional shortcuts. Our bias analysis shows this would specifically improve D recall (currently only 0.48). |\n",
    "| **Chain-of-thought fine-tuning** | +3-8% | Training on \"Question -> Explanation -> Answer\" sequences rather than direct letter prediction. This engages the model's reasoning capabilities and has been shown to improve medical QA accuracy. Requires CoT-annotated training data (e.g., from GPT-4 explanations). |\n",
    "| **Retrieval-Augmented Generation (RAG)** | +5-15% | Augmenting each question with retrieved medical textbook passages at inference time. This directly addresses the knowledge ceiling by providing external evidence the base model lacks. |\n",
    "| **Medical-domain base model (BioMistral)** | +3-8% | Starting from BioMistral-7B (pre-trained on PubMed) instead of general Mistral-7B provides a richer medical knowledge base before fine-tuning. |\n",
    "| **Larger base model (70B)** | +5-10% | Fine-tuning Llama-3-70B or Mixtral-8x7B with QLoRA would provide more pre-trained medical knowledge, but at 4-8x the compute cost. |\n",
    "| **Ensemble of top configs** | +1-3% | Majority vote across the top 3 configs (4, 3, 2) could correct individual model errors. Increases inference cost linearly but requires no retraining. |\n",
    "| **Data augmentation (MedMCQA)** | +2-5% | Adding 183K Indian medical exam questions from MedMCQA would broaden the training distribution, especially for underrepresented topics. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Ethical Considerations\n",
    "\n",
    "1. **Clinical risk.** At 57.4% accuracy, the model answers incorrectly on nearly half of medical questions. It must **not** be used for clinical decision-making. Even significantly higher accuracy (e.g., 90%) would require rigorous clinical validation before any deployment.\n",
    "\n",
    "2. **Cultural bias.** USMLE-based training data reflects US-centric medical practice, drug formularies, and clinical guidelines. The model's performance would likely degrade on questions about non-US treatment protocols or disease prevalence patterns.\n",
    "\n",
    "3. **Overconfidence.** The calibration analysis (ECE = 0.254) shows the model cannot reliably signal when it is uncertain. In a medical context, a confident wrong answer could lead to harm if the model were misused for decision support.\n",
    "\n",
    "4. **Demographic blind spots.** Clinical vignettes in MedQA may underrepresent certain patient demographics (age groups, ethnicities, socioeconomic backgrounds), potentially leading to performance disparities across populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Reproducibility\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Base model | `mistralai/Mistral-7B-Instruct-v0.3` |\n",
    "| Dataset | `GBaker/MedQA-USMLE-4-options-hf` (10,178 / 1,272 / 1,273) |\n",
    "| Method | QLoRA (4-bit NF4, bfloat16 compute, double quantization) |\n",
    "| Best config | lr=5e-5, r=16, alpha=32, cosine schedule, 3 epochs, early stopping (patience=3) |\n",
    "| Trainer | HuggingFace `trl.SFTTrainer` v0.28 with `SFTConfig` |\n",
    "| Optimizer | Paged AdamW 8-bit |\n",
    "| Libraries | transformers, peft, trl, bitsandbytes, accelerate |\n",
    "| Seed | 42 |\n",
    "| Compute | Google Colab, NVIDIA H100 80GB HBM3 |\n",
    "| Total training time | ~3.5 hours (all 6 configs) |\n",
    "| Code | Available in `src/` directory with modular architecture |\n",
    "| Results | Saved to Google Drive (`/content/drive/MyDrive/cs614_results/`) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}